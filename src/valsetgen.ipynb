{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.tree import *\n",
    "from ordered_set import OrderedSet\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/miniconda3/envs/spacy/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/scratch/miniconda3/envs/spacy/lib/python3.11/site-packages/thinc/shims/pytorch.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# spacy setup\n",
    "gpu = spacy.prefer_gpu(0)\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternating_verbs = '''feed,give,lease,lend,loan,pass,pay,peddle,refund,render,rent,repay,sell,serve,trade,advance,allocate,allot,assign,award,bequeath,cede,concede,extend,grant,guarantee,issue,leave,offer,owe,promise,vote,will,yield,bring,take,forward,hand,mail,post,send,ship,slip,smuggle,sneak,bounce,float,roll,slide,carry,drag,haul,heave,heft,hoise,kick,lug,pull,push,schlep,shove,tote,tow,tug,barge,bus,cart,drive,ferry,fly,row,shuttle,truck,wheel,wire,bash,bat,bunt,catapult,chuck,flick,fling,flip,hit,hurl,kick,lob,pass,pitch,punt,shoot,shove,slam,slap,sling,throw,tip,toss,ask,cite,pose,preach,quote,read,relay,show,teach,tell,write,cable,email,e-mail,fax,modem,netmail,phone,radio,relay,satellite,semaphore,sign,signal,telephone,telecast,telegraph,telex,wire,wireless'''.split(\",\")\n",
    "\n",
    "do_only_verbs = '''accord,ask,bear,begrudge,bode,cost,deny,envy,flash,forbid,forgive,guarantee,issue,refuse,save,spare,strike,vouchsafe,wish,write,bet,bill,charge,fine,mulct,overcharge,save,spare,tax,tip,undercharge,wager,acknowledge,adopt,appoint,consider,crown,deem,designate,elect,esteeem,imagine,mark,nominate,ordain,proclaim,rate,recon,report,want,anoint,baptize,brand,call,christen,consecrate,crown,decree,dub,label,make,name,nickname,pronounce,rule,stamp,style,term,vote,adjudge,adjudicate,assume,avow,believe,confess,declare,fancy,find,judge,presume,profess,prove,suppose,think,warrant'''.split(\",\")\n",
    "\n",
    "pp_only_verbs = '''address,administer,broadcast,convey,contribute,delegate,deliver,denounce,demonstrate,describe,dictate,dispatch,display,distribute,donate,elucidate,exhibit,express,explain,explicate,forfeit,illustrate,introduce,narrate,portray,proffer,recite,recommend,refer,reimburse,remit,restore,return,sacrifice,submit,surrender,transfer,transport,admit,allege,announce,articulate,assert,communicate,confess,convey,declare,mention,propose,recount,repeat,report,reveal,say,state,babble,bark,bawl,bellow,bleat,boom,bray,burble,cackle,call,carol,chant,chatter,chrip,cluck,coo,croak,croon,crow,cry,drawl,drone,gabble,gibber,groan,growl,grumble,grunt,hiss,holler,hoot,howl,jabber,lilt,lisp,moan,mumble,murmur,mutter,purr,rage,rasp,roar,rumble,scream,screech,shout,shriek,sing,snap,snarl,snuffle,splutter,squall,squawk,squeak,squeal,stammer,stutter,thunder,tisk,trill,trumpet,twitter,wail,warble,wheeze,whimper,whine,whisper,whistle,whoop,yammer,yap,yell,yelp,yodel,drop,hoist,lift,lower,raise,credit,entrust,furnish,issue,leave,present,provide,serve,supply,trust'''.split(\",\")\n",
    "\n",
    "dative_verbs = sorted(list(set(alternating_verbs + do_only_verbs + pp_only_verbs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children_flatten(token, depth=0, dep=False, return_tokens=False):\n",
    "    children = []\n",
    "    for child in token.children:\n",
    "        if dep:\n",
    "            if return_tokens:\n",
    "                children.append((child.text.lower(), child.dep_, child.tag_, depth, child.i, child))\n",
    "            else:\n",
    "                children.append((child.text.lower(), child.dep_, child.tag_, depth, child.i))\n",
    "        else:\n",
    "            children.append(child.text.lower())\n",
    "        children.extend(get_children_flatten(child, depth+1, dep, return_tokens))\n",
    "    return children\n",
    "\n",
    "\n",
    "def detect_dative(sentence,nlp):\n",
    "    dative=False\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            children = get_children_flatten(token, 0, dep=True)\n",
    "            if len(children) > 0:\n",
    "                tokens, dep, pos_string, depth, index = list(zip(*children))\n",
    "                if \"to\" in tokens:\n",
    "                    dep_depth = [f\"{d}_{str(depth[i])}\" for i, d in enumerate(dep)]\n",
    "                    tok_dep = [f\"{tokens[i]}_{dep[i]}\" for i in range(len(tokens))]\n",
    "                    if (\"dobj_0\" in dep_depth and \"dative_0\" in dep_depth and \"pobj_1\" in dep_depth) or (\"dobj_0\" in dep_depth and \"prep_0\" in dep_depth and \"pobj_1\" in dep_depth):\n",
    "                        if \"to_dative\" in tok_dep or \"to_prep\" in tok_dep:\n",
    "                            dative=True\n",
    "                else:\n",
    "                    dep_depth = [f\"{d}_{str(depth[i])}\" for i, d in enumerate(dep)]\n",
    "                    tokens_dep = [f\"{tokens[i]}_{dep[i]}\" for i in range(len(tokens))]\n",
    "                    if (\"dobj_0\" in dep_depth and \"dative_0\" in dep_depth) or Counter(dep_depth)['dobj_0'] >= 2:\n",
    "                        if 'for_dative' not in tokens_dep and 'for_dobj' not in tokens_dep:\n",
    "                            dative=True\n",
    "\n",
    "\n",
    "    return dative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_childes(path):\n",
    "    data = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            data.append(line.strip().lower())\n",
    "\n",
    "    return data\n",
    "\n",
    "# with open(\"../data/lexicon/adaptation.json\") as f:\n",
    "#     adaptation = json.load(f)\n",
    "\n",
    "adaptation_vocab = OrderedSet()\n",
    "# for k, v in adaptation.items():\n",
    "#     for vv in v:\n",
    "#         vv = re.sub(r'(the\\s|of)+', '', vv).strip()\n",
    "#         words = vv.split()\n",
    "#         for word in words:\n",
    "#             # if word not in ['I', 'me', 'her', 'she', 'it']:\n",
    "#             adaptation_vocab.add(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedSet()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "childes_train = read_childes(\n",
    "    \"../data/corpora/aochildes.train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    \"brown-adam.parsed\",\n",
    "    \"brown-eve+animacy+theta.parsed\",\n",
    "    \"brown-sarah.parsed\",\n",
    "    \"soderstrom.parsed\",\n",
    "    \"suppes.parsed\",\n",
    "    \"valian+animacy+theta.parsed\",\n",
    "    \"hslld-hv1-er.parsed\",\n",
    "    \"hslld-hv1-mt.parsed\",\n",
    "]\n",
    "\n",
    "cats = [\"n\", \"v\", \"adj\", \"adv\"]\n",
    "\n",
    "_TAG_TO_CAT = {\n",
    "    \"NN\": \"n\",\n",
    "    \"NNS\": \"n\",\n",
    "    \"VB\": \"v\",\n",
    "    #     'VBD': 'v',\n",
    "    \"JJ\": \"adj\",\n",
    "    \"RB\": \"adv\",\n",
    "}\n",
    "\n",
    "relevant = list(_TAG_TO_CAT.keys())\n",
    "\n",
    "TREEBANK_PATH = \"../data/corpora/childes-treebank\"\n",
    "\n",
    "trees = []\n",
    "tree = \"\"\n",
    "\n",
    "for file in os.listdir(TREEBANK_PATH):\n",
    "    #     if \"parsed\" in file:\n",
    "    if file in filenames:\n",
    "        with open(f\"{TREEBANK_PATH}/{file}\", \"r\") as f:\n",
    "            for line in f:\n",
    "                # If you have completed a tree, add it to the list of trees\n",
    "                if line.strip() == \"\":\n",
    "                    if (\n",
    "                        tree.strip() != \"\"\n",
    "                        and tree.count(\")\") == tree.count(\"(\")\n",
    "                        and tree.count(\"ROOT\") == 1\n",
    "                    ):\n",
    "                        trees.append(tree)\n",
    "                    tree = \"\"\n",
    "                else:\n",
    "                    tree += line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = Tree.fromstring(trees[11])\n",
    "parsed.leaves()\n",
    "\n",
    "_, linearised_pos = list(zip(*parsed.pos()))\n",
    "\n",
    "\" \".join(linearised_pos)\n",
    "\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    sentence = (\n",
    "        sentence.replace(\" 're\", \"'re\")\n",
    "        .replace(\" 's\", \"'s\")\n",
    "        .replace(\" 'll\", \"'ll\")\n",
    "        .replace(\" 've\", \"'ve\")\n",
    "        .replace(\"_\", \" \")\n",
    "        .replace(\"ING\", \"ing\")\n",
    "        .replace(\" 't\", \"'t\")\n",
    "        .replace(\" 'm\", \"'m\")\n",
    "        .replace(\"*pro*\", \"\")\n",
    "        .replace(\"*t*-1\", \" \")\n",
    "        .replace(\"*\", \" \")\n",
    "        .replace(\"^P^\", \" \")\n",
    "        .replace(\" n't\", \"n't\")\n",
    "        .replace(\" 'd\", \"'d\")\n",
    "        .lower()\n",
    "        .strip()\n",
    "    )\n",
    "    sentence = re.sub(\" {2,}\", \" \", sentence).strip().replace(\"t -1\", \" \")\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def linearize(tree):\n",
    "    parsed = Tree.fromstring(tree)\n",
    "    leaves, pos = list(zip(*parsed.pos()))\n",
    "    # sent = \" \".join(leaves)\n",
    "    return leaves, \" \".join(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_verb(sent, pos, span):\n",
    "    start_idx = len(pos[: span[0]-1].split(\" \"))\n",
    "    initial = list(sent[:start_idx])\n",
    "    end_idx = len(pos[span[1]+1:].split(\" \"))\n",
    "    end = list(sent[-end_idx:])\n",
    "    verb = sent[start_idx:start_idx+1]\n",
    "    return verb, initial + ['[verb]'] + end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex = r'(?<=*)(VB|VBZ|VBD)(?=^(PRP))'\n",
    "regex = r\"(?<=\\w\\W)(\\b(VBD|VBZ|VB)\\b)(?=((?!(\\s)?(PRP|\\.|$|VB))))\"\n",
    "vb_regex = r\"(?<=\\w\\W)(\\bVB\\b)(?=((?!(\\s)?(PRP|\\.|,|\\!|\\?|$|VB|-<V\\d>))))\"\n",
    "vbd_regex = r\"(?<=\\w\\W)(\\bVBD\\b)(?=((?!(\\s)?(PRP|\\.|,|\\!|\\?|$|VB|-<V\\d>))))\"\n",
    "vbz_regex = r\"(?<=\\w\\W)(\\bVBZ\\b)(?=((?!(\\s)?(PRP|\\.|,|\\!|\\?|$|VB|-<V\\d>))))\"\n",
    "nn_regex = r\"(?<=\\w\\W)(\\bNN\\b)(?=.*)\"\n",
    "adj_regex = r\"(?<=\\w\\W)(\\bJJ\\b)(?=.*)\"\n",
    "\n",
    "verbs = {\n",
    "    \"VB\": [],\n",
    "    \"VBD\": [],\n",
    "    \"VBZ\": [],\n",
    "}\n",
    "\n",
    "non_verbs = {\"NN\": [], \"JJ\": []}\n",
    "\n",
    "for i, tree in enumerate(trees):\n",
    "    try:\n",
    "        sent, pos = linearize(tree)\n",
    "        regex_searches = {\n",
    "            \"VB\": re.search(vb_regex, pos),\n",
    "            \"VBD\": re.search(vbd_regex, pos),\n",
    "            \"VBZ\": re.search(vbz_regex, pos),\n",
    "        }\n",
    "        for k, v in regex_searches.items():\n",
    "            if v:\n",
    "                if \"W\" not in pos and \"?\" not in sent:\n",
    "                    span = v.span()\n",
    "                    # verbs[k].append((sent, pos, span))\n",
    "                    verb, inserted = insert_verb(sent, pos, span)\n",
    "                    sentence = clean_sentence(\" \".join(inserted))\n",
    "                    sent_words = sentence.split(\" \")\n",
    "                    # dont add sentences with adaptation words\n",
    "                    found = False\n",
    "                    for word in sent_words:\n",
    "                        if word in adaptation_vocab:\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        sentence = re.sub(',', ' ', sentence)\n",
    "                        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "                        if \"[verb] to\" not in sentence and \"[verb]n't\" not in sentence and \"[verb] off\" not in sentence and \"[verb] up\" not in sentence and \"[verb] down\" not in sentence and \"[verb] out\" not in sentence and \"[verb] in\" not in sentence and \"[verb] for\" not in sentence and \"[verb] down\" not in sentence and \"[verb] over\" not in sentence and \"[verb] under\" not in sentence and \"[verb] back\" not in sentence and \"[verb] on\" not in sentence:\n",
    "                            if verb[0] not in ['came', 'falled', 'become', 'became', 'was', 'were', 'seemed', 'knew', 'did']:\n",
    "                                verbs[k].append([i, sentence, verb])\n",
    "\n",
    "        # noun regexes\n",
    "        # nn_search = re.search(nn_regex, pos)\n",
    "        non_verb_searches = {\n",
    "            \"NN\": re.search(nn_regex, pos),\n",
    "            \"JJ\": re.search(adj_regex, pos),\n",
    "        }\n",
    "        for k, v in non_verb_searches.items():\n",
    "            if v:\n",
    "                if \"W\" not in pos and \"?\" not in sent:\n",
    "                    span = v.span()\n",
    "                    # non_verbs[k].append((sent, pos, span))\n",
    "                    non_verb, inserted = insert_verb(sent, pos, span)\n",
    "                    sentence = clean_sentence(\" \".join(inserted))\n",
    "                    sent_words = sentence.split(\" \")\n",
    "                    # dont add sentences with adaptation words\n",
    "                    found = False\n",
    "                    for word in sent_words:\n",
    "                        if word in adaptation_vocab:\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        sentence = re.sub(',', ' ', sentence)\n",
    "                        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "                        if \"[verb] to\" not in sentence:\n",
    "                            non_verbs[k].append([i, sentence, non_verb])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # if re.search(vbd_regex, pos):\n",
    "    #     verbs[\"VBD\"].append((sent, pos))\n",
    "    # if re.search(vbz_regex, pos):\n",
    "    #     verbs[\"VBZ\"].append((sent, pos))\n",
    "    # if re.search(vb_regex, pos):\n",
    "    #     verbs[\"VB\"].append((sent, pos))\n",
    "    # if re.search(regex, pos):\n",
    "    #     print(sent)\n",
    "    #     print(pos)\n",
    "    #     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'VB': 6608, 'VBD': 1499, 'VBZ': 1025}, {'NN': 29452, 'JJ': 13826})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k : len(v) for k, v in verbs.items()}, {k : len(v) for k, v in non_verbs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbs['VBD']\n",
    "\n",
    "verb_sents = defaultdict(OrderedSet)\n",
    "for idx, sentence, word in verbs['VBD']:\n",
    "    for w in word:\n",
    "        verb_sents[w].add(sentence)\n",
    "verb_sents = dict(verb_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_dative = defaultdict(list)\n",
    "\n",
    "for verb, sents in verb_sents.items():\n",
    "    for sent in sents:\n",
    "        dative = detect_dative(sent, nlp)\n",
    "        is_dative[verb].append(dative)\n",
    "is_dative = dict(is_dative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbs['VBD']\n",
    "# sample 150 verbs\n",
    "verb_sentences = []\n",
    "for k,v in verb_sents.items():\n",
    "    verb_sentences.extend(v)\n",
    "\n",
    "sampled_verbs = random.sample(verb_sentences, 200)\n",
    "# sampled_verbs = []\n",
    "# for k, v in verbs.items():\n",
    "    # sampled_verbs.extend(random.sample(v, 50))\n",
    "\n",
    "# sample 150 non-verbs\n",
    "sampled_non_verbs = []\n",
    "for k, v in non_verbs.items():\n",
    "    sampled_non_verbs.extend(random.sample(v, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38656, 'you little [verb] .', ('kid',)],\n",
       " [107820, 'but a [verb] throws with his', ('seal',)],\n",
       " [37026, \"i don't have a wide [verb] .\", ('pencil',)],\n",
       " [1037, 'well wait for just a [verb] .', ('second',)],\n",
       " [10882, 'and a [verb] .', ('banana',)],\n",
       " [129180,\n",
       "  'he was talking about the first [verb] of school about a couple of days',\n",
       "  ('day',)],\n",
       " [115691, \"you wouldn't go inside the [verb] .\", ('cage',)],\n",
       " [8601, \"i don't think it's really a [verb] .\", ('horse',)],\n",
       " [38452, 'ya got her head right in the [verb] .', ('water',)],\n",
       " [10260, \"that's from [verb] of the books .\", ('one',)],\n",
       " [4481, \"okay eve's [verb] .\", ('turn',)],\n",
       " [157705, 'be here all [verb] .', ('day',)],\n",
       " [55965,\n",
       "  \"they started out with about five in the [verb] and i guess gradually they've able dropped out and finally she's alone .\",\n",
       "  ('class',)],\n",
       " [10871, \"they're peeking out of the [verb] door .\", ('kitchen',)],\n",
       " [92413,\n",
       "  'and then we went outside and colby fell in the [verb] and got all',\n",
       "  ('ocean',)],\n",
       " [39971, \"so [verb]'s three .\", ('that',)],\n",
       " [46534, 'you must a had a wonderful [verb] .', ('time',)],\n",
       " [121402,\n",
       "  \"that's a [verb] but i was asking you if you saw an eagle with\",\n",
       "  ('guitar',)],\n",
       " [87152, 'this put in the [verb] .', ('suitcase',)],\n",
       " [36135, 'my grandmother used to do [verb] by the hour with us .', ('this',)],\n",
       " [96599, 'because we just had a [verb] .', ('bath',)],\n",
       " [20502, 'no no [verb] .', ('money',)],\n",
       " [131629, 'a [verb] .', ('yak',)],\n",
       " [161278,\n",
       "  'they put [verb] in it and they take some things away from it .',\n",
       "  ('salt',)],\n",
       " [104081, \"oh we're going to have lots of [verb] up .\", ('fence',)],\n",
       " [105249, \"no that's a [verb] with a hair dryer on her head .\", ('lady',)],\n",
       " [85485, \"there's the [verb] .\", ('elephant',)],\n",
       " [40708, \"that's [verb] of right .\", ('kind',)],\n",
       " [143577, \"it's a [verb] .\", ('necktie',)],\n",
       " [85527, \"that's a big [verb] .\", ('penguin',)],\n",
       " [149201, 'now you can wash your teeth [verb] .', ('Mariana',)],\n",
       " [69754, 'a [verb] .', ('slinky',)],\n",
       " [32417, \"well [verb]'s not it .\", ('that',)],\n",
       " [14602, 'a [verb] .', ('monkey',)],\n",
       " [14883, 'i want a [verb] .', ('bottle',)],\n",
       " [119922, \"watch and you'll see them come out of the [verb] .\", ('hive',)],\n",
       " [76546, 'look at [verb] .', ('that',)],\n",
       " [59476, 'i like the [verb] he frowns .', ('way',)],\n",
       " [74721, \"in [verb] i think i'm going to mush it up\", ('fact',)],\n",
       " [70673, 'hello [verb] says hello .', ('mommy',)],\n",
       " [84784, 'look at [verb] .', ('this',)],\n",
       " [158230, 'so give it a [verb] !', ('try',)],\n",
       " [133082, 'you got her head in [verb] .', ('there',)],\n",
       " [7950, 'put that over on the [verb] .', ('table',)],\n",
       " [122528, \"that's a [verb] .\", ('schoolbus',)],\n",
       " [119115, \"four o' [verb] .\", ('clock',)],\n",
       " [117756, 'she we should keep her in this [verb] .', ('box',)],\n",
       " [15157, \"here's the little [verb] .\", ('doggie',)],\n",
       " [8877, \"yep that's [verb] .\", ('everything',)],\n",
       " [68794, \"don't wreck your horse like [verb] please .\", ('that',)],\n",
       " [132846, 'or [verb] .', ('something',)],\n",
       " [57411, \"mm [verb]'s perfume .\", ('that',)],\n",
       " [148118, 'please turn off the [verb] .', ('tv',)],\n",
       " [157956, \"i'm going to the [verb] i said .\", ('store',)],\n",
       " [16622, \"oh [verb]'s jo ann .\", ('that',)],\n",
       " [41672, \"you'll be in [verb] for a week .\", ('bed',)],\n",
       " [32606, 'she must have picked it up on [verb] .', ('television',)],\n",
       " [32403, 'with the little [verb] .', ('hole',)],\n",
       " [96205, \"i guess there's another [verb] with some homes .\", ('box',)],\n",
       " [81591, \"okay [verb] i'm going to close this now .\", ('honey',)],\n",
       " [21941, 'you look like a little [verb] .', ('orphan',)],\n",
       " [74111, 'you bumped yourself right on the [verb] .', ('face',)],\n",
       " [31075, 'auntie marion has a [verb] like that .', ('kitty',)],\n",
       " [46543, 'that [verb] .', ('sequence',)],\n",
       " [84028, \"don't tear the [verb] .\", ('book',)],\n",
       " [41837, \"alright you're not going to [verb] at the square .\", ('anything',)],\n",
       " [159671, 'you made [verb] !', ('cornbread',)],\n",
       " [11690,\n",
       "  \"it's not drink your head it's stick your head in [verb] .\",\n",
       "  ('gravy',)],\n",
       " [80105, \"fishies don't like the [verb] .\", ('banging',)],\n",
       " [149267, \"seven o' [verb] every night !\", ('clock',)],\n",
       " [157908, \"i don't want [verb] .\", ('that',)],\n",
       " [157119, \"i'll make some [verb] and beans .\", ('rice',)],\n",
       " [99389, \"that's a [verb] .\", ('kangaroo',)],\n",
       " [15078, \"here's [verb] .\", ('milk',)],\n",
       " [7449,\n",
       "  \"no this [verb]'s for papa but as soon as i finish this one i'll\",\n",
       "  ('one',)],\n",
       " [118925, 'this is a [verb] .', ('tree',)],\n",
       " [96938,\n",
       "  \"i've never heard of a little [verb] eating radishes and cake .\",\n",
       "  ('girl',)],\n",
       " [153561, 'alright wait a [verb] .', ('minute',)],\n",
       " [2120, 'well maybe but not for [verb] .', ('lunch',)],\n",
       " [14506, 'a [verb] .', ('chair',)],\n",
       " [137677, 'and you can bring them [verb] .', ('home',)],\n",
       " [155743, \"it's a [verb] book !\", ('peekaboo',)],\n",
       " [39719, 'tell kent all about [verb] .', ('school',)],\n",
       " [27778, \"in a few minutes we'll take [verb] off .\", ('this',)],\n",
       " [69613, \"he's got to be bouncing to the [verb] .\", ('music',)],\n",
       " [87169, \"you pretend you're the [verb] .\", ('teacher',)],\n",
       " [86782, \"no that's not a blue [verb] .\", ('bird',)],\n",
       " [36062, 'this is a [verb] .', ('lion',)],\n",
       " [158352,\n",
       "  \"i was going to say we'd take a [verb] up to richardson's but\",\n",
       "  ('ride',)],\n",
       " [68387, 'we could write your [verb] on .', ('name',)],\n",
       " [8570, \"you do have an easter [verb] but it's put away\", ('basket',)],\n",
       " [27513, 'let me see [verb] .', ('that',)],\n",
       " [64302, \"oh you're getting heavy little [verb] .\", ('boy',)],\n",
       " [307, 'more [verb] .', ('pudding',)],\n",
       " [66312,\n",
       "  \"bitty [verb] is three and blitzen's one month and catherine is .\",\n",
       "  ('bear',)],\n",
       " [44397, \"oh [verb] willn't hurt .\", ('that',)],\n",
       " [143464, \"don't chew the [verb] child .\", ('car',)],\n",
       " [143685, 'the greek [verb] .', ('guy',)],\n",
       " [82900, 'goes [verb] tweet .', ('tweet',)],\n",
       " [47793, 'wait a [verb] .', ('while',)],\n",
       " [82227, \"we'll do a [verb] bit more .\", ('little',)],\n",
       " [136790, 'he was [verb] of it so i hid it .', ('afraid',)],\n",
       " [143196, 'well a [verb] bit .', ('little',)],\n",
       " [153869, \"oh chi that's [verb] .\", ('awful',)],\n",
       " [111160, \"but if it rains it'll be awfully [verb] .\", ('muddy',)],\n",
       " [130412, \"mm that's a [verb] boat .\", ('big',)],\n",
       " [140722, \"you're [verb] .\", ('heavy',)],\n",
       " [95866, \"that's [verb] .\", ('right',)],\n",
       " [32071, \"she's [verb] .\", ('pretty',)],\n",
       " [39436, \"i'm [verb] .\", ('hot',)],\n",
       " [58028, \"they're on the [verb] side .\", ('other',)],\n",
       " [43901, 'you have the [verb] glass .', ('same',)],\n",
       " [11675, \"oh i'm [verb] .\", ('sorry',)],\n",
       " [115391, 'no both you and spencer have [verb] snoopies .', ('big',)],\n",
       " [143987, \"it's a [verb] hedgehog .\", ('funny',)],\n",
       " [108287, \"that's [verb] food .\", ('breakfast',)],\n",
       " [12045, \"yes they're [verb] dishes .\", ('round',)],\n",
       " [148373, 'i know i know my gun is this [verb] .', ('high',)],\n",
       " [60633, 'he is a [verb] boy !', ('big',)],\n",
       " [11561, \"that's [verb] .\", ('right',)],\n",
       " [10216, 'you still have the [verb] part .', ('big',)],\n",
       " [116422, \"and it's going to be really [verb] .\", ('yummy',)],\n",
       " [93672, \"better be [verb] that's right .\", ('careful',)],\n",
       " [99198, \"let's show the donkey all the [verb] animals .\", ('other',)],\n",
       " [106050, \"yum yum yum the honey's [verb] .\", ('good',)],\n",
       " [32502, 'red [verb] oh sarah .', ('red',)],\n",
       " [11504,\n",
       "  \"well it's not such a [verb] idea for you to bounce on it i think\",\n",
       "  ('good',)],\n",
       " [100784, \"and then we'll wrap him up in [verb] paper .\", ('blue',)],\n",
       " [15646, 'we have something [verb] for you .', ('nice',)],\n",
       " [38713, \"oh that's really a [verb] song .\", ('good',)],\n",
       " [13063, 'be very [verb] .', ('careful',)],\n",
       " [118073,\n",
       "  \"here's the money for the lady if she wants to go [verb] things .\",\n",
       "  ('buy',)],\n",
       " [12998, \"yeah that's a [verb] lady .\", ('big',)],\n",
       " [132857, \"that's [verb] .\", ('right',)],\n",
       " [46873, 'the [verb] ones are no good .', ('plastic',)],\n",
       " [77905, 'look at that [verb] elephant .', ('funny',)],\n",
       " [24807, 'yeah do it [verb] .', ('good',)],\n",
       " [113469, \"oh you're a pretty [verb] kitty cat .\", ('funny',)],\n",
       " [49085, \"let me take it off because i'm [verb] you'll .\", ('afraid',)],\n",
       " [115302, \"that's [verb] .\", ('ok',)],\n",
       " [117934, \"well that's [verb] .\", ('good',)],\n",
       " [8269, 'but you do not have a [verb] one .', ('brown',)],\n",
       " [122530, \"that's [verb] .\", ('right',)],\n",
       " [16132, \"that's the [verb] doggie and there's the little doggie .\", ('big',)],\n",
       " [81394, \"it's [verb] .\", ('good',)],\n",
       " [129710, \"you're absolutely [verb] .\", ('right',)],\n",
       " [116352, \"that's not [verb] fun .\", ('much',)],\n",
       " [112657, \"that's [verb] .\", ('good',)],\n",
       " [103968, 'look at the [verb] clown .', ('funny',)],\n",
       " [61025,\n",
       "  \"yeah i don't think daddy did a [verb] enough job here joseph .\",\n",
       "  ('good',)],\n",
       " [51948, \"today she wasn't [verb] .\", ('sick',)],\n",
       " [41730, 'right in the [verb] yard .', ('back',)],\n",
       " [131912, 'a [verb] girl and a little boy .', ('little',)],\n",
       " [140317, \"oh it's not [verb] eyes .\", ('green',)],\n",
       " [60707, 'that would be a [verb] one to take on our vacation ', ('good',)],\n",
       " [47488, \"well that's [verb] .\", ('black',)],\n",
       " [52803, \"it isn't very [verb] either .\", ('sticky',)],\n",
       " [76266, \"that's [verb] good .\", ('right',)],\n",
       " [27471, \"that's not very [verb] .\", ('nice',)],\n",
       " [132331, \"that's [verb] .\", ('right',)],\n",
       " [127946, \"oh yeah that's [verb] .\", ('right',)],\n",
       " [58532, \"she's a [verb] orphan .\", ('poor',)],\n",
       " [88963, \"you're [verb] .\", ('welcome',)],\n",
       " [60998, \"you're [verb] sweetie .\", ('okay',)],\n",
       " [149031, \"i'm the [verb] mommy .\", ('real',)],\n",
       " [13678, \"oh isn't that [verb] .\", ('awful',)],\n",
       " [2309,\n",
       "  \"that sock's already [verb] and it's much bigger than the other one .\",\n",
       "  ('on',)],\n",
       " [89296, \"that's a [verb] girl .\", ('little',)],\n",
       " [123207,\n",
       "  \"and you're going to get you're going t -2 to be [verb] .\",\n",
       "  ('sore',)],\n",
       " [112296,\n",
       "  \"oh i'm [verb] they would like to play with some animals .\",\n",
       "  ('sure',)],\n",
       " [19784, 'yeah you got so [verb] junk .', ('much',)],\n",
       " [13738, \"now let's make a [verb] bottle .\", ('big',)],\n",
       " [107316, 'bob and scott did a [verb] time ago .', ('long',)],\n",
       " [42961, \"that's very [verb] .\", ('good',)],\n",
       " [99990, \"i don't see any [verb] blocks here .\", ('wooden',)],\n",
       " [52699,\n",
       "  'i jumped out of bed and he had the [verb] thing made by the time i got there .',\n",
       "  ('whole',)],\n",
       " [27839, \"it's [verb] .\", ('alright',)],\n",
       " [66498,\n",
       "  'thomas you can not play with all these [verb] peices out here near .',\n",
       "  ('little',)],\n",
       " [13113, \"that's [verb] .\", ('right',)],\n",
       " [48778, 'she can write her name pretty [verb] .', ('good',)],\n",
       " [70878, 'well he just put [verb] batteries so it should be okay .', ('new',)],\n",
       " [55879, 'her dancing costume her gypsy one came in [verb] .', ('terrible',)],\n",
       " [32513, 'give mommy a [verb] one .', ('red',)],\n",
       " [85249, 'thank you for the [verb] comb .', ('little',)],\n",
       " [162256, 'pretty [verb] .', ('awesome',)],\n",
       " [108472,\n",
       "  \"because [verb] babies aren't supposed to get into medicine .\",\n",
       "  ('little',)],\n",
       " [138014,\n",
       "  'well you ended up with such a [verb] little art object there .',\n",
       "  ('nice',)],\n",
       " [59003, 'she did the [verb] day .', ('other',)],\n",
       " [120847,\n",
       "  'they have a they have a [verb] room for jumping with a swing and a',\n",
       "  ('big',)],\n",
       " [157790, \"you're [verb] .\", ('okay',)],\n",
       " [129324, 'you should try pro to play a [verb] more gently .', ('little',)],\n",
       " [105624, 'oh those are [verb] .', ('cute',)],\n",
       " [2031, 'very [verb] .', ('good',)],\n",
       " [131449,\n",
       "  'yeah i have to get ready pro to go home in a [verb] while .',\n",
       "  ('little',)],\n",
       " [159403, \"no i'll do it [verb] .\", ('okay',)],\n",
       " [111011, \"that's a [verb] umbrella .\", ('pretty',)],\n",
       " [58469, 'a three is too [verb] and a four is too long .', ('small',)],\n",
       " [130910, \"she's always going to be the [verb] underdog .\", ('little',)],\n",
       " [20887, \"yeah it's too [verb] for you yeah .\", ('big',)],\n",
       " [28360, 'oops be [verb] .', ('careful',)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampled_verbs\n",
    "sampled_non_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,s,v in sampled_verbs:\n",
    "#     if \"-1\" in s:\n",
    "#         print(s, v)\n",
    "\n",
    "# sampled_non_verbs\n",
    "val_set = {\n",
    "    'good': [s for s in sampled_verbs],\n",
    "    'bad': [s for i, s, v in sampled_non_verbs]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/experiments/verbhood.json\", \"w\") as f:\n",
    "    json.dump(val_set, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('and', 'the', 'pedalpushers', 'go', 'in', 'your', '.'),\n",
       " 'CC DT NNS VB-<V1> IN PRP$ .')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearize(trees[81762])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and now it's [verb] for miss catherine !\""
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentence(non_verbs['NN'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_seq = 'NNP , PRP$ NN VBD RB .'\n",
    "# sentence = 'Joseph , your balloon fell down .'\n",
    "# span = (14,17)\n",
    "# start_idx = len(pos_seq[:13].split(\" \"))\n",
    "# initial = sentence.split(\" \" )[:start_idx]\n",
    "\n",
    "# end_idx = len(pos_seq[18:].split(\" \"))\n",
    "# end = sentence.split(\" \")[-end_idx:]\n",
    "\n",
    "# initial + ['[verb]'] + end\n",
    "# sentence.split(\" \")[4:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sent, pos, span in verbs['VBD'][:20]:\n",
    "#     verb, inserted = insert_verb(sent, pos, span)\n",
    "#     print(\" \".join(inserted), verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
