{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import utils\n",
    "import random\n",
    "import pathlib\n",
    "\n",
    "from ordered_set import OrderedSet\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lexicon(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lexicon = json.load(f)\n",
    "        lexicon = {k: OrderedSet(v) for k, v in lexicon.items()}\n",
    "        long = OrderedSet(\n",
    "            [\n",
    "                x\n",
    "                for x in lexicon[\"animate\"].union(lexicon[\"inanimate\"])\n",
    "                if len(x.split(\" \")) > 2\n",
    "            ]\n",
    "        )\n",
    "        short = OrderedSet(\n",
    "            [\n",
    "                x\n",
    "                for x in lexicon[\"animate\"].union(lexicon[\"inanimate\"])\n",
    "                if len(x.split(\" \")) <= 2\n",
    "            ]\n",
    "        )\n",
    "        nominals = OrderedSet(\n",
    "            [\n",
    "                x\n",
    "                for x in lexicon[\"animate\"].union(lexicon[\"inanimate\"])\n",
    "                - lexicon[\"pronoun\"]\n",
    "            ]\n",
    "        )\n",
    "        lexicon.update({\"long\": long, \"short\": short, \"nominal\": nominals})\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation_lexicon = read_lexicon(\"../data/lexicon/adaptation-final.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2feature = defaultdict(OrderedSet)\n",
    "for feature, words in adaptation_lexicon.items():\n",
    "    for word in words:\n",
    "        word2feature[word].add(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedSet(['inanimate', 'definite', 'theme', 'recipient', 'marked', 'short', 'nominal'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2feature = dict(word2feature)\n",
    "word2feature['the teddy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inanimate_nominals = adaptation_lexicon[\"inanimate\"].intersection(adaptation_lexicon[\"nominal\"]).intersection(adaptation_lexicon[\"short\"]).intersection(adaptation_lexicon[\"marked\"])\n",
    "\n",
    "animate_nominals = adaptation_lexicon[\"animate\"].intersection(adaptation_lexicon[\"nominal\"]).intersection(adaptation_lexicon[\"short\"]) - OrderedSet([\"cat\", \"dog\", \"bear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedSet(['me', 'her', 'him', 'them', 'us', 'mommy', 'grandpa', 'grandma', 'the cat', 'the dog', 'elmo', 'bert', 'daddy', 'cat', 'dog', 'the bear', 'bear'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_lexicon['animate'].intersection(adaptation_lexicon['short']).intersection(adaptation_lexicon['definite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedSet(['it', 'something', 'cheerios', 'teddy', 'cup', 'book', 'toys in the room', 'cup on the table', 'food on the table', 'balls in the room', 'legos', 'ball', 'store', 'pencils', 'dolly'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_lexicon['inanimate'].intersection(adaptation_lexicon['unmarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronoun_items = {\n",
    "    'him': [\"daddy\", \"grandpa\", \"ryan\", \"john\", \"teddy\", \"the dog\", \"the cat\"],\n",
    "    'her': [\"mommy\", \"grandma\", \"sarah\", \"jessica\", \"the bear\", \"the cat\", \"the doll\"],\n",
    "    'me': ['me'],\n",
    "    'us': ['us'],\n",
    "    'them': ['some balls', 'some toys', 'the cats', 'the dogs', 'the dolls', 'someone', 'some people'],\n",
    "    'it': ['the doll', 'the book', 'the ball', 'a ball', 'a doll', 'a book']\n",
    "}\n",
    "\n",
    "def pronoun2name(name):\n",
    "    if name == \"he\":\n",
    "        return random.choice([\"daddy\", \"sam\"])\n",
    "    elif name == \"she\":\n",
    "        return random.choice([\"mommy\", \"lucy\", \"nonna\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2280"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation1 = utils.read_jsonl(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_no_discourse/adaptation.jsonl\")\n",
    "adaptation2 = utils.read_jsonl(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_no_discourse2/adaptation.jsonl\")\n",
    "\n",
    "adaptation3 = utils.read_jsonl(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_no_discourse3/adaptation.jsonl\")\n",
    "\n",
    "adaptation3_id2item = {a['item']: a for a in adaptation3}\n",
    "adaptation3_ids = adaptation3_id2item.keys()\n",
    "\n",
    "adaptation12 = adaptation1 + adaptation2\n",
    "\n",
    "adaptation = []\n",
    "for a in adaptation12:\n",
    "    if a['item'] in adaptation3_ids:\n",
    "        adaptation.append(adaptation3_id2item[a['item']])\n",
    "    else:\n",
    "        adaptation.append(a)\n",
    "\n",
    "len(adaptation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control:\n",
    "random.seed(42)\n",
    "adaptation_control = []\n",
    "for a in adaptation:\n",
    "    a_copy = a.copy()\n",
    "    if a['agent'] in ['he', 'she']:\n",
    "        agent = pronoun2name(a['agent'])\n",
    "    else:\n",
    "        agent = a['agent']\n",
    "    a_copy['sentence'] = f\"look {agent} is walking around . {a_copy['sentence']}\"\n",
    "    a_copy['sampled_agent'] = agent\n",
    "    adaptation_control.append(a_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_discourse_control\").mkdir(parents=True, exist_ok=True)\n",
    "with open(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_discourse_control/adaptation.jsonl\", \"w\") as f:\n",
    "    for a in adaptation_control:\n",
    "        f.write(json.dumps(a) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
