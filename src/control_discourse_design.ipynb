{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import utils\n",
    "import random\n",
    "import pathlib\n",
    "\n",
    "from ordered_set import OrderedSet\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lexicon(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lexicon = json.load(f)\n",
    "        lexicon = {k: OrderedSet(v) for k, v in lexicon.items()}\n",
    "        long = OrderedSet(\n",
    "            [\n",
    "                x\n",
    "                for x in lexicon[\"animate\"].union(lexicon[\"inanimate\"])\n",
    "                if len(x.split(\" \")) > 2\n",
    "            ]\n",
    "        )\n",
    "        short = OrderedSet(\n",
    "            [\n",
    "                x\n",
    "                for x in lexicon[\"animate\"].union(lexicon[\"inanimate\"])\n",
    "                if len(x.split(\" \")) <= 2\n",
    "            ]\n",
    "        )\n",
    "        nominals = OrderedSet(\n",
    "            [\n",
    "                x\n",
    "                for x in lexicon[\"animate\"].union(lexicon[\"inanimate\"])\n",
    "                - lexicon[\"pronoun\"]\n",
    "            ]\n",
    "        )\n",
    "        lexicon.update({\"long\": long, \"short\": short, \"nominal\": nominals})\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation_lexicon = read_lexicon(\"../data/lexicon/adaptation-final-nomarkedness.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2feature = defaultdict(OrderedSet)\n",
    "for feature, words in adaptation_lexicon.items():\n",
    "    for word in words:\n",
    "        word2feature[word].add(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedSet(['inanimate', 'recipient', 'theme', 'definite', 'short', 'nominal'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2feature = dict(word2feature)\n",
    "word2feature['the chair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w,f in word2feature.items():\n",
    "    if \"agent\" not in f:\n",
    "        if len(f) < 5:\n",
    "            print(w, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inanimate_nominals = adaptation_lexicon[\"inanimate\"].intersection(adaptation_lexicon[\"nominal\"]).intersection(adaptation_lexicon[\"short\"])\n",
    "\n",
    "animate_nominals = adaptation_lexicon[\"animate\"].intersection(adaptation_lexicon[\"nominal\"]).intersection(adaptation_lexicon[\"short\"]) - OrderedSet([\"cat\", \"dog\", \"bear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedSet(['a ball', 'the ball', 'a book', 'the book', 'a cup', 'the cup', 'a toy', 'the toys', 'some books', 'some balls', 'some milk', 'some food', 'the food', 'the milk', 'the cheerios', 'the legos', 'a lego', 'the pencils', 'a pencil', 'a chair', 'the chair', 'some cheerios'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inanimate_nominals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedSet(['me', 'her', 'him', 'them', 'us', 'mommy', 'grandpa', 'grandma', 'the cat', 'the dog', 'daddy'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_lexicon['animate'].intersection(adaptation_lexicon['short']).intersection(adaptation_lexicon['definite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptation_lexicon['inanimate'].intersection(adaptation_lexicon['unmarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronoun_items = {\n",
    "    'him': [\"daddy\", \"grandpa\", \"ryan\", \"john\", \"teddy\", \"the dog\", \"the cat\"],\n",
    "    'her': [\"mommy\", \"grandma\", \"sarah\", \"jessica\", \"the bear\", \"the cat\", \"the doll\"],\n",
    "    'me': ['me'],\n",
    "    'us': ['us'],\n",
    "    'them': ['some balls', 'some toys', 'the cats', 'the dogs', 'the dolls', 'someone', 'some people'],\n",
    "    'it': ['the doll', 'the book', 'the ball', 'a ball', 'a doll', 'a book']\n",
    "}\n",
    "\n",
    "def pronoun2name(name, remove=[]):\n",
    "    if name == \"he\":\n",
    "        choices = [n for n in [\"daddy\", \"john\"] if n not in remove]\n",
    "        return random.choice(choices)\n",
    "    elif name == \"she\":\n",
    "        choices = [n for n in [\"mommy\", \"lucy\"] if n not in remove]\n",
    "        return random.choice(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1620"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adaptation1 = utils.read_jsonl(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_no_discourse/adaptation.jsonl\")\n",
    "# adaptation2 = utils.read_jsonl(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_no_discourse2/adaptation.jsonl\")\n",
    "\n",
    "# adaptation3 = utils.read_jsonl(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_no_discourse3/adaptation.jsonl\")\n",
    "\n",
    "# adaptation3_id2item = {a['item']: a for a in adaptation3}\n",
    "# adaptation3_ids = adaptation3_id2item.keys()\n",
    "\n",
    "# adaptation12 = adaptation1 + adaptation2\n",
    "\n",
    "# adaptation = []\n",
    "# for a in adaptation12:\n",
    "#     if a['item'] in adaptation3_ids:\n",
    "#         adaptation.append(adaptation3_id2item[a['item']])\n",
    "#     else:\n",
    "#         adaptation.append(a)\n",
    "\n",
    "# len(adaptation)\n",
    "\n",
    "adaptation = utils.read_jsonl(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_no_markedness_no_discourse/adaptation.jsonl\")\n",
    "len(adaptation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control:\n",
    "random.seed(42)\n",
    "adaptation_control = []\n",
    "neutral_control = []\n",
    "for a in adaptation:\n",
    "    a_copy = a.copy()\n",
    "    n_copy = a.copy()\n",
    "    if a['agent'] in ['he', 'she']:\n",
    "        agent = pronoun2name(a['agent'], [a['theme'], a['recipient']])\n",
    "    else:\n",
    "        agent = a['agent']\n",
    "    a_copy['sentence'] = f\"look {agent} is walking around . {a_copy['sentence']}\"\n",
    "    a_copy['sampled_agent'] = agent\n",
    "    n_copy['sentence'] = f\"it was a nice day . {n_copy['sentence']}\"\n",
    "    n_copy['sampled_agent'] = agent\n",
    "    adaptation_control.append(a_copy)\n",
    "    neutral_control.append(n_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_no_markedness_discourse_control\").mkdir(parents=True, exist_ok=True)\n",
    "with open(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_no_markedness_discourse_control/adaptation.jsonl\", \"w\") as f:\n",
    "    for a in adaptation_control:\n",
    "        f.write(json.dumps(a) + \"\\n\")\n",
    "\n",
    "pathlib.Path(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_no_markedness_neutral_discourse\").mkdir(parents=True, exist_ok=True)\n",
    "with open(\"../data/experiments/single_stimuli_dative_simulation_valtest_vbd_no_markedness_neutral_discourse/adaptation.jsonl\", \"w\") as f:\n",
    "    for a in neutral_control:\n",
    "        f.write(json.dumps(a) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
