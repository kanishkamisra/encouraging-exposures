{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import config\n",
    "# import inflect\n",
    "import json\n",
    "import math\n",
    "# import os\n",
    "import random\n",
    "import utils\n",
    "import pathlib\n",
    "\n",
    "from collections import defaultdict\n",
    "from string import Template\n",
    "from dataclasses import dataclass\n",
    "from itertools import product\n",
    "from ordered_set import OrderedSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Dative:\n",
    "    dative: str\n",
    "    verb: str\n",
    "    agent: str\n",
    "    theme: str\n",
    "    recipient: str\n",
    "\n",
    "    def generate(self, marked_theme=False, marked_recipient=False):\n",
    "        if self.dative == \"do\":\n",
    "            template = Template(\"$agent $verb $recipient $theme .\")\n",
    "        elif self.dative == \"pp\":\n",
    "            template = Template(\"$agent $verb $theme to $recipient .\")\n",
    "\n",
    "        if marked_theme:\n",
    "            self.theme = f\"the {self.theme}\"\n",
    "\n",
    "        if marked_recipient:\n",
    "            self.recipient = f\"the {self.recipient}\"\n",
    "\n",
    "        self.sentence = template.substitute(\n",
    "            agent=self.agent, verb=self.verb, theme=self.theme, recipient=self.recipient\n",
    "        )\n",
    "        return self.sentence\n",
    "\n",
    "    def givenness(self, discourse_sentence=None):\n",
    "        return NotImplementedError\n",
    "\n",
    "\n",
    "def read_lexicon(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lexicon = json.load(f)\n",
    "        lexicon = {k: OrderedSet(v) for k, v in lexicon.items()}\n",
    "        long = OrderedSet(\n",
    "            [\n",
    "                x\n",
    "                for x in lexicon[\"animate\"].union(lexicon[\"inanimate\"])\n",
    "                if len(x.split(\" \")) > 2\n",
    "            ]\n",
    "        )\n",
    "        short = OrderedSet(\n",
    "            [\n",
    "                x\n",
    "                for x in lexicon[\"animate\"].union(lexicon[\"inanimate\"])\n",
    "                if len(x.split(\" \")) <= 2\n",
    "            ]\n",
    "        )\n",
    "        nominals = OrderedSet(\n",
    "            [\n",
    "                x\n",
    "                for x in lexicon[\"animate\"].union(lexicon[\"inanimate\"])\n",
    "                - lexicon[\"pronoun\"]\n",
    "            ]\n",
    "        )\n",
    "        lexicon.update({\"long\": long, \"short\": short, \"nominal\": nominals})\n",
    "    return lexicon\n",
    "\n",
    "\n",
    "def generate_feature_combinations(lex, features):\n",
    "    feature_combinations = []\n",
    "    for fc in product(features, features):\n",
    "        theme_features, recipient_features = fc\n",
    "        theme_features = [lex[feature] for feature in theme_features]\n",
    "        recipient_features = [lex[feature] for feature in recipient_features]\n",
    "        theme_features = OrderedSet.intersection(*theme_features)\n",
    "        recipient_features = OrderedSet.intersection(*recipient_features)\n",
    "        if len(theme_features) >= 1 and len(recipient_features) >= 1:\n",
    "            if len(theme_features) == 1 and len(recipient_features) == 1:\n",
    "                continue\n",
    "            else:\n",
    "                feature_combinations.append(fc)\n",
    "    return feature_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation_lexicon = read_lexicon(\"../data/lexicon/adaptation.json\")\n",
    "generalization_lexicon = read_lexicon(\"../data/lexicon/generalization.json\")\n",
    "\n",
    "# full_lexicon = {\n",
    "#     k: adaptation_lexicon[k].union(generalization_lexicon[k])\n",
    "#     for k in adaptation_lexicon.keys()\n",
    "# }\n",
    "\n",
    "pronominality = [\"pronoun\", \"nominal\"]\n",
    "animacy = [\"animate\", \"inanimate\"]\n",
    "length = [\"long\", \"short\"]\n",
    "\n",
    "# generate all possible combinations of features for theme and recipient and then prune\n",
    "features = list(product(pronominality, animacy, length))\n",
    "\n",
    "feature_combinations = generate_feature_combinations(adaptation_lexicon, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plausibility = {\"do\": {'plausible': [], 'implausible': []}, \"pp\": {'plausible': [], 'implausible': []}}\n",
    "for dative in ['do', 'pp']:\n",
    "    for fc in feature_combinations:\n",
    "        fc_id = utils.generate_acronym_tuple(fc)\n",
    "        if fc_id in config.IMPLAUSIBLE[dative]:\n",
    "            plausibility[dative]['implausible'].append(fc_id)\n",
    "        else:\n",
    "            plausibility[dative]['plausible'].append(fc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plausibility['do']['implausible'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specify_sample_size(plausibility, N=20):\n",
    "    sample_sizes = {'do': defaultdict(int), 'pp': defaultdict(int)}\n",
    "    for dative, splits in plausibility.items():\n",
    "        n_plausible, n_implausible = len(splits['plausible']), len(splits['implausible'])\n",
    "\n",
    "        addition = n_implausible * N/n_plausible\n",
    "        plausible_amt = int(n_plausible * math.floor(N + addition))\n",
    "\n",
    "        print(dative, plausible_amt)\n",
    "\n",
    "        for acronym in splits['plausible']:\n",
    "            sample_sizes[dative][acronym] = math.floor(N + addition)\n",
    "        for acronym in splits['implausible']:\n",
    "            sample_sizes[dative][acronym] = 0\n",
    "        sample_sizes[dative] = dict(sample_sizes[dative])\n",
    "    return sample_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do 688\n",
      "pp 680\n"
     ]
    }
   ],
   "source": [
    "sample_sizes = specify_sample_size(plausibility, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nalpas': 43,\n",
       " 'nalpis': 43,\n",
       " 'nalnal': 43,\n",
       " 'nalnas': 43,\n",
       " 'naspas': 43,\n",
       " 'naspis': 43,\n",
       " 'nasnal': 43,\n",
       " 'nasnas': 43,\n",
       " 'nilpas': 43,\n",
       " 'nilpis': 43,\n",
       " 'nilnal': 43,\n",
       " 'nilnas': 43,\n",
       " 'nispas': 43,\n",
       " 'nispis': 43,\n",
       " 'nisnal': 43,\n",
       " 'nisnas': 43,\n",
       " 'paspas': 0,\n",
       " 'paspis': 0,\n",
       " 'pasnal': 0,\n",
       " 'pasnas': 0,\n",
       " 'pasnil': 0,\n",
       " 'pasnis': 0,\n",
       " 'pispas': 0,\n",
       " 'pisnal': 0,\n",
       " 'pisnas': 0,\n",
       " 'pisnil': 0,\n",
       " 'pisnis': 0,\n",
       " 'nalnil': 0,\n",
       " 'nalnis': 0,\n",
       " 'nasnil': 0,\n",
       " 'nasnis': 0,\n",
       " 'nilnil': 0,\n",
       " 'nilnis': 0,\n",
       " 'nisnil': 0,\n",
       " 'nisnis': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sizes['do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
