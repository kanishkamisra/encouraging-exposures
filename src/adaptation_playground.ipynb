{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import config\n",
    "\n",
    "# import inflect\n",
    "import json\n",
    "import math\n",
    "\n",
    "# import os\n",
    "import random\n",
    "import utils\n",
    "import pathlib\n",
    "\n",
    "from collections import defaultdict\n",
    "from string import Template\n",
    "from dataclasses import dataclass\n",
    "from itertools import product\n",
    "from ordered_set import OrderedSet\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Dative:\n",
    "    dative: str\n",
    "    verb: str\n",
    "    agent: str\n",
    "    theme: str\n",
    "    recipient: str\n",
    "\n",
    "    def generate(self, marked_theme=False, marked_recipient=False):\n",
    "        if self.dative == \"do\":\n",
    "            template = Template(\"$agent $verb $recipient $theme .\")\n",
    "        elif self.dative == \"pp\":\n",
    "            template = Template(\"$agent $verb $theme to $recipient .\")\n",
    "\n",
    "        if marked_theme:\n",
    "            self.theme = f\"the {self.theme}\"\n",
    "\n",
    "        if marked_recipient:\n",
    "            self.recipient = f\"the {self.recipient}\"\n",
    "\n",
    "        self.sentence = template.substitute(\n",
    "            agent=self.agent, verb=self.verb, theme=self.theme, recipient=self.recipient\n",
    "        )\n",
    "        return self.sentence\n",
    "\n",
    "    def givenness(self, discourse_sentence=None):\n",
    "        return NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lexicon(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lexicon = json.load(f)\n",
    "        lexicon = {k: OrderedSet(v) for k, v in lexicon.items()}\n",
    "        long = OrderedSet(\n",
    "            [\n",
    "                x\n",
    "                for x in lexicon[\"animate\"].union(lexicon[\"inanimate\"])\n",
    "                if len(x.split(\" \")) > 2\n",
    "            ]\n",
    "        )\n",
    "        short = OrderedSet(\n",
    "            [\n",
    "                x\n",
    "                for x in lexicon[\"animate\"].union(lexicon[\"inanimate\"])\n",
    "                if len(x.split(\" \")) <= 2\n",
    "            ]\n",
    "        )\n",
    "        nominals = OrderedSet(\n",
    "            [\n",
    "                x\n",
    "                for x in lexicon[\"animate\"].union(lexicon[\"inanimate\"])\n",
    "                - lexicon[\"pronoun\"]\n",
    "            ]\n",
    "        )\n",
    "        lexicon.update({\"long\": long, \"short\": short, \"nominal\": nominals})\n",
    "    return lexicon\n",
    "\n",
    "\n",
    "def generate_feature_combinations(lex, features, allcombos=False):\n",
    "    feature_combinations = []\n",
    "    for fc in product(features, features):\n",
    "        theme_features, recipient_features = fc\n",
    "        theme_features = [lex[feature] for feature in theme_features] + [lex[\"theme\"]]\n",
    "        recipient_features = [lex[feature] for feature in recipient_features] + [lex[\"recipient\"]]\n",
    "        theme_features = OrderedSet.intersection(*theme_features)\n",
    "        recipient_features = OrderedSet.intersection(*recipient_features)\n",
    "        if allcombos:\n",
    "            feature_combinations.append(fc)\n",
    "        else:\n",
    "            if len(theme_features) >= 1 and len(recipient_features) >= 1:\n",
    "                # print(fc, len(theme_features), len(recipient_features))\n",
    "                if len(theme_features) == 1 and len(recipient_features) == 1:\n",
    "                    continue\n",
    "                else:\n",
    "                # print(fc[-1], recipient_features)\n",
    "                    feature_combinations.append(fc)\n",
    "    return feature_combinations\n",
    "\n",
    "\n",
    "def plausibility_splits(\n",
    "    feature_combinations,\n",
    "    implausible_combinations=config.IMPLAUSIBLE,\n",
    "    adaptation=True,\n",
    "):\n",
    "    plausibility = {\n",
    "        \"do\": {\"plausible\": [], \"implausible\": []},\n",
    "        \"pp\": {\"plausible\": [], \"implausible\": []},\n",
    "    }\n",
    "    for dative in [\"do\", \"pp\"]:\n",
    "        for fc in feature_combinations:\n",
    "            fc_id = utils.generate_acronym_tuple(fc)\n",
    "            if not adaptation:\n",
    "                if fc_id in implausible_combinations[dative]:\n",
    "                    plausibility[dative][\"implausible\"].append(fc_id)\n",
    "                else:\n",
    "                    plausibility[dative][\"plausible\"].append(fc_id)\n",
    "            else:\n",
    "                plausibility[dative][\"plausible\"].append(fc_id)\n",
    "    return plausibility\n",
    "\n",
    "\n",
    "def specify_sample_size(plausibility, N=20):\n",
    "    sample_sizes = {\"do\": defaultdict(int), \"pp\": defaultdict(int)}\n",
    "    amts = []\n",
    "    for dative, splits in plausibility.items():\n",
    "        n_plausible, n_implausible = len(splits[\"plausible\"]), len(\n",
    "            splits[\"implausible\"]\n",
    "        )\n",
    "\n",
    "        addition = n_implausible * N / n_plausible\n",
    "        plausible_amt = int(n_plausible * math.floor(N + addition))\n",
    "        amts.append(plausible_amt)\n",
    "\n",
    "        # print(dative, plausible_amt)\n",
    "\n",
    "        for acronym in splits[\"plausible\"]:\n",
    "            sample_sizes[dative][acronym] = math.floor(N + addition)\n",
    "        for acronym in splits[\"implausible\"]:\n",
    "            sample_sizes[dative][acronym] = 0\n",
    "        sample_sizes[dative] = dict(sample_sizes[dative])\n",
    "    return sample_sizes, amts\n",
    "\n",
    "\n",
    "def generate_feature_space(feature_combo, lex):\n",
    "    theme_features, recipient_features = feature_combo\n",
    "    theme_features = [lex[feature] for feature in theme_features] + [lex[\"theme\"]]\n",
    "    recipient_features = [lex[feature] for feature in recipient_features] + [\n",
    "        lex[\"recipient\"]\n",
    "    ]\n",
    "    return (\n",
    "        lex[\"agent\"],\n",
    "        OrderedSet.intersection(*theme_features),\n",
    "        OrderedSet.intersection(*recipient_features),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dative_set(lexicon, feature_combinations, sample_sizes):\n",
    "    dative_set = []\n",
    "    for i, fc in enumerate(feature_combinations):\n",
    "        fc_id = utils.generate_acronym_tuple(fc)\n",
    "        # if fc_id != \"paspas\":\n",
    "        #     break\n",
    "        feature_space = generate_feature_space(fc, lexicon)\n",
    "        # if len(feature_space[1]) == 1 and len(feature_space[2]) == 1 and feature_space[1] == feature_space[2]:\n",
    "        #     pass\n",
    "        # else:\n",
    "        N = max(sample_sizes[\"do\"][fc_id], sample_sizes[\"pp\"][fc_id])\n",
    "        if N == 0:\n",
    "            pass\n",
    "        else:\n",
    "            sampled_items = sample_items(*feature_space, N)\n",
    "            # print(fc, len(sampled_items[0]), len(sampled_items[1]), len(sampled_items[2]))\n",
    "            j = 0\n",
    "            for dative in [\"do\", \"pp\"]:\n",
    "                # items = sampled_items[: sample_sizes[dative][fc_id]]\n",
    "                items = [\n",
    "                    argument[: sample_sizes[dative][fc_id]]\n",
    "                    for argument in sampled_items\n",
    "                ]\n",
    "                # print(dative, len(items[0]))\n",
    "                # for j, (a, t, r) in enumerate(zip(*items)):\n",
    "                for agent, theme, recipient in zip(*items):\n",
    "                    # check if any of them is empty\n",
    "                    if agent == \"\" or theme == \"\" or recipient == \"\":\n",
    "                        continue\n",
    "                    do_dative = Dative(\n",
    "                        dative, \"[verb]\", agent, theme, recipient\n",
    "                    ).generate()\n",
    "                    # pp_dative = Dative(\"pp\", \"[verb]\", a, t, r).generate()\n",
    "                    dative_set.append(\n",
    "                        {\n",
    "                            \"item\": len(dative_set) + 1,\n",
    "                            \"hypothesis_id\": i + 1,\n",
    "                            \"hypothesis_instance\": j + 1,\n",
    "                            \"theme_pronominality\": fc[0][0],\n",
    "                            \"theme_animacy\": fc[0][1],\n",
    "                            \"theme_length\": fc[0][2],\n",
    "                            \"theme_definiteness\": fc[0][3],\n",
    "                            \"recipient_pronominality\": fc[1][0],\n",
    "                            \"recipient_animacy\": fc[1][1],\n",
    "                            \"recipient_length\": fc[1][2],\n",
    "                            \"recipient_definiteness\": fc[1][3],\n",
    "                            \"agent\": agent,\n",
    "                            \"theme\": theme,\n",
    "                            \"recipient\": recipient,\n",
    "                            \"dative\": dative,\n",
    "                            \"sentence\": do_dative,\n",
    "                        }\n",
    "                    )\n",
    "                    j += 1\n",
    "                j = 0\n",
    "    return dative_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': 6, 'pronoun': 8, 'animate': 34, 'inanimate': 35, 'recipient': 69, 'theme': 69, 'definite': 38, 'indefinite': 31, 'long': 27, 'short': 42, 'nominal': 61}\n",
      "135 16\n",
      "Adaptation: 135 135\n"
     ]
    }
   ],
   "source": [
    "N = 6\n",
    "\n",
    "adaptation_lexicon = read_lexicon(\"../data/lexicon/adaptation-final-nomarkedness.json\")\n",
    "# generalization_lexicon = read_lexicon(\"data/lexicon/adaptation-final-nomarkedness.json\")\n",
    "\n",
    "print({k: len(v) for k, v in adaptation_lexicon.items()})\n",
    "\n",
    "pronominality = [\"pronoun\", \"nominal\"]\n",
    "animacy = [\"animate\", \"inanimate\"]\n",
    "length = [\"long\", \"short\"]\n",
    "definiteness = [\"definite\", \"indefinite\"]\n",
    "# markedness = [\"marked\", \"unmarked\"]\n",
    "\n",
    "features = list(product(pronominality, animacy, length, definiteness))\n",
    "# features = list(product(pronominality, animacy, length, definiteness))\n",
    "\n",
    "feature_combinations = generate_feature_combinations(adaptation_lexicon, features)\n",
    "\n",
    "feature_combinations_final = []\n",
    "buffer = []\n",
    "for fc in feature_combinations:\n",
    "    if utils.generate_acronym_tuple(fc) in config.ORIGINALLY_MISSED:\n",
    "        buffer.append(fc)\n",
    "    else:\n",
    "        feature_combinations_final.append(fc)\n",
    "feature_combinations = feature_combinations_final + buffer\n",
    "\n",
    "print(len(feature_combinations), len(features))\n",
    "\n",
    "\n",
    "adapt_plausible_splits = plausibility_splits(feature_combinations, adaptation=True)\n",
    "print(\n",
    "    \"Adaptation:\",\n",
    "    len(adapt_plausible_splits[\"do\"][\"plausible\"]),\n",
    "    len(adapt_plausible_splits[\"pp\"][\"plausible\"]),\n",
    ")\n",
    "\n",
    "adapt_sample_sizes, adapt_amt = specify_sample_size(\n",
    "    adapt_plausible_splits, N\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_items(agents, themes, recipients, N):\n",
    "    # sample themes\n",
    "    if len(themes) < N:\n",
    "        # sampled_themes = random.choices(themes, k=N)\n",
    "        sampled_themes = random.sample(themes, min(N, len(themes))) + random.choices(themes, k=N - len(themes))\n",
    "    else:\n",
    "        sampled_themes = random.sample(themes, N)\n",
    "    sampled_recipients = []\n",
    "    sampled_agents = []\n",
    "    for sampled_theme in sampled_themes:\n",
    "        conflict_set = OrderedSet(\n",
    "            config.CONFLICTS[sampled_theme]\n",
    "            if sampled_theme in config.CONFLICTS.keys()\n",
    "            else []\n",
    "        )\n",
    "        # print(sampled_theme, recipients, conflict_set)\n",
    "        recipient_space = recipients - OrderedSet([sampled_theme]) - conflict_set\n",
    "        if len(recipient_space) == 0:\n",
    "            sampled_recipient = \"\"\n",
    "        else:\n",
    "            sampled_recipient = random.choice(list(recipient_space))\n",
    "            # print(sampled_recipient)\n",
    "\n",
    "        if sampled_theme in config.CONFLICTS.keys():\n",
    "            conflict_set = conflict_set.union(\n",
    "                OrderedSet(config.CONFLICTS[sampled_theme])\n",
    "            )\n",
    "        if sampled_recipient in config.CONFLICTS.keys():\n",
    "            conflict_set = conflict_set.union(\n",
    "                OrderedSet(config.CONFLICTS[sampled_recipient])\n",
    "            )\n",
    "        # print(sampled_theme, conflict_set)\n",
    "        # agent_space = (\n",
    "        #     agents - OrderedSet([sampled_theme] + [sampled_recipient]) - conflict_set\n",
    "        # )\n",
    "        # sampled_agent = random.choice(list(agent_space))\n",
    "\n",
    "        # sampled_agents.append(sampled_agent)\n",
    "        sampled_recipients.append(sampled_recipient)\n",
    "\n",
    "    agent_conflicts = OrderedSet()\n",
    "    for sampled_theme, sampled_recipient in zip(sampled_themes, sampled_recipients):\n",
    "        conflict_set = OrderedSet(\n",
    "            config.CONFLICTS[sampled_theme]\n",
    "            if sampled_theme in config.CONFLICTS.keys()\n",
    "            else []\n",
    "        )\n",
    "        conflict_set = conflict_set.union(\n",
    "            OrderedSet(config.CONFLICTS[sampled_recipient])\n",
    "            if sampled_recipient in config.CONFLICTS.keys()\n",
    "            else []\n",
    "        )\n",
    "        agent_conflicts.update(\n",
    "            OrderedSet([sampled_theme] + [sampled_recipient]).union(conflict_set)\n",
    "        )\n",
    "\n",
    "    agent_space = agents - agent_conflicts\n",
    "    # print(\n",
    "    #     \"themes\",\n",
    "    #     sampled_themes,\n",
    "    #     \"recipients\",\n",
    "    #     sampled_recipients,\n",
    "    #     \"agents space\",\n",
    "    #     agent_space,\n",
    "    # )\n",
    "    if len(agent_space) < N:\n",
    "        sampled_agents = random.choices(list(agent_space), k=N)\n",
    "    else:\n",
    "        sampled_agents = random.sample(list(agent_space), N)\n",
    "\n",
    "    return sampled_agents, sampled_themes, sampled_recipients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/135 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/135 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     sampled_items \u001b[38;5;241m=\u001b[39m \u001b[43msample_items\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfeature_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m#     sampled_items = sample_items(*feature_space, n)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# except:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m#     print(n)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# print(fc_id, sampled_items)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m, in \u001b[0;36msample_items\u001b[0;34m(agents, themes, recipients, N)\u001b[0m\n\u001b[1;32m     10\u001b[0m conflict_set \u001b[38;5;241m=\u001b[39m OrderedSet(\n\u001b[1;32m     11\u001b[0m     config\u001b[38;5;241m.\u001b[39mCONFLICTS[sampled_theme]\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sampled_theme \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mCONFLICTS\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print(sampled_theme, recipients, conflict_set)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m recipient_space \u001b[38;5;241m=\u001b[39m \u001b[43mrecipients\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mOrderedSet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msampled_theme\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m conflict_set\n\u001b[1;32m     17\u001b[0m recipient_space \u001b[38;5;241m=\u001b[39m recipients \u001b[38;5;241m-\u001b[39m OrderedSet([sampled_theme]) \u001b[38;5;241m-\u001b[39m conflict_set\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(recipient_space) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m<frozen _collections_abc>:607\u001b[0m, in \u001b[0;36m__sub__\u001b[0;34m(self, other)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# first sample a few themes\n",
    "lexicon = adaptation_lexicon\n",
    "sample_sizes = adapt_sample_sizes\n",
    "dative_set = []\n",
    "for i, fc in enumerate(tqdm(feature_combinations)):\n",
    "    fc_id = utils.generate_acronym_tuple(fc)\n",
    "    # if fc_id != \"paspas\":\n",
    "    #     break\n",
    "    feature_space = generate_feature_space(fc, lexicon)\n",
    "    # if len(feature_space[1]) == 1 and len(feature_space[2]) == 1 and feature_space[1] == feature_space[2]:\n",
    "    #     pass\n",
    "    # else:\n",
    "    n = max(sample_sizes[\"do\"][fc_id], sample_sizes[\"pp\"][fc_id])\n",
    "    if n == 0:\n",
    "        pass\n",
    "    else:\n",
    "        sampled_items = sample_items(*feature_space, n)\n",
    "        # try:\n",
    "        #     sampled_items = sample_items(*feature_space, n)\n",
    "        # except:\n",
    "        #     print(n)\n",
    "\n",
    "        # print(fc_id, sampled_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_space\n",
    "# fc\n",
    "# len(sampled_items)\n",
    "len(feature_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmisra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
