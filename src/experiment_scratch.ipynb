{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from minicons import scorer\n",
    "from torch import optim\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW, get_constant_schedule, set_seed\n",
    "from experiment import Learner\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(\"kanishka/smolm-autoreg-bpe-seed_111\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.add_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 180, 8193, 51, 353, 70, 141, 38]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [[1, 180, 8192, 51, 353, 70, 141, 38]]\n",
    "\n",
    "[[ii + 1 if ii == 8192 else ii for ii in i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.4966742992401123]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.sequence_score(\"she gave me the ball .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = scorer.IncrementalLMScorer(\"kanishka/smolm-autoreg-bpe-seed_111\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('<s>', 0.0),\n",
       "  ('she', -4.799075126647949),\n",
       "  ('gave', -6.241611480712891),\n",
       "  ('the', -2.643448829650879),\n",
       "  ('ball', -3.6407971382141113),\n",
       "  ('to', -0.5346994400024414),\n",
       "  ('me', -2.1648502349853516),\n",
       "  ('.', -0.6528644561767578)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.token_score(\"she gave the ball to me .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0782,  0.0603, -0.0287,  ...,  0.0975, -0.0735, -0.0400],\n",
       "        [-0.0611, -0.0391, -0.1022,  ...,  0.0748, -0.0744,  0.0567],\n",
       "        [ 0.0663,  0.0578, -0.0290,  ...,  0.1053, -0.0621, -0.0745],\n",
       "        ...,\n",
       "        [-0.0048,  0.2357,  0.0625,  ...,  0.1035, -0.0358,  0.0389],\n",
       "        [-0.0794, -0.0094, -0.0807,  ...,  0.0767,  0.0060, -0.0285],\n",
       "        [ 0.1411, -0.0778,  0.0027,  ...,  0.1294,  0.0140,  0.0097]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.model.resize_token_embeddings().weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(8193, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new tokens\n",
    "length = lm.model.resize_token_embeddings().weight.shape[0]\n",
    "added_tokens = [\" [verb]\"]\n",
    "lm.tokenizer.add_tokens(added_tokens)\n",
    "\n",
    "# avoids including <|endoftext|> which is present in the tokenizer\n",
    "new_length = length+len(added_tokens)\n",
    "lm.model.resize_token_embeddings(new_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = new_length-len(added_tokens)\n",
    "embeddings_weight = lm.model.resize_token_embeddings().weight\n",
    "embeddings_weight.requires_grad = False\n",
    "\n",
    "mu = embeddings_weight[:index].mean(0).detach()\n",
    "n = length\n",
    "sigma = ((embeddings_weight[:index] - mu).T @ (embeddings_weight[:index] - mu)) / n\n",
    "dist = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "        mu, covariance_matrix=1e-5*sigma)\n",
    "\n",
    "embeddings_weight[index:] = torch.stack(tuple((dist.sample() for _ in range(len(added_tokens)))), dim=0)\n",
    "embeddings_weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0782,  0.0603, -0.0287,  ...,  0.0975, -0.0735, -0.0400],\n",
       "        [-0.0611, -0.0391, -0.1022,  ...,  0.0748, -0.0744,  0.0567],\n",
       "        [ 0.0663,  0.0578, -0.0290,  ...,  0.1053, -0.0621, -0.0745],\n",
       "        ...,\n",
       "        [-0.0794, -0.0094, -0.0807,  ...,  0.0767,  0.0060, -0.0285],\n",
       "        [ 0.1411, -0.0778,  0.0027,  ...,  0.1294,  0.0140,  0.0097],\n",
       "        [ 0.0350,  0.0372, -0.0193,  ...,  0.0344, -0.0282, -0.0269]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(8193, 256)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.model.model.decoder.embed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_params = ['model.decoder.embed_tokens.weight']\n",
    "\n",
    "for param in lm.model.named_parameters():\n",
    "    if param[0] not in target_params:\n",
    "        param[1].requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [param[0] for param in lm.model.named_parameters() if param[1].requires_grad] == target_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[1, 180, 8193, 51, 353, 70, 277, 0, 0, 0, 0], [1, 174, 8193, 51, 253, 1428, 353, 70, 51, 390, 7]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.tokenizer([\"she [verb] the ball to him\", \"they [verb] the big beautiful ball to the cat.\"], padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = lm.tokenizer([\"she [verb] the ball to him\", \"they [verb] the big beautiful ball to the cat.\"], padding=True, return_tensors=\"pt\")\n",
    "\n",
    "encoded['input_ids'] = torch.tensor([[t-1 if t == new_length else t for t in token_ids] for token_ids in encoded.input_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded, offset = lm.prepare_text(\"she [verb] the ball to him .\")\n",
    "encoded['input_ids'] = torch.tensor([[t-1 if t > length else t for t in token_ids] for token_ids in encoded.input_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ -4.7991, -14.9654,  -6.6724,  -6.5123,  -4.8335,  -5.2774,  -0.5907])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.compute_stats((encoded, offset), return_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation = utils.read_jsonl(\"../data/experiments/adaptation.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(adaptation, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch['pp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "x = [1,2,3,4]\n",
    "y = [5,6,7,8]\n",
    "\n",
    "results.extend(list(zip(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.extend(list(zip(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 5), (2, 6), (3, 7), (4, 8), (1, 5), (2, 6), (3, 7), (4, 8)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
